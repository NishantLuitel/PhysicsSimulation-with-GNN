{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc300867",
   "metadata": {},
   "source": [
    "# Understanding the Cylinder Flow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f5b7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b607977",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6cf6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'Cylinder_flow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1357e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adopted Functions from Deep mind to load the dataset.\n",
    "def _parse(proto, meta):\n",
    "  \"\"\"Parses a trajectory from tf.Example.\"\"\"\n",
    "  feature_lists = {k: tf.io.VarLenFeature(tf.string)\n",
    "                   for k in meta['field_names']}\n",
    "  features = tf.io.parse_single_example(proto, feature_lists)\n",
    "  out = {}\n",
    "  for key, field in meta['features'].items():\n",
    "    data = tf.io.decode_raw(features[key].values, getattr(tf, field['dtype']))\n",
    "    data = tf.reshape(data, field['shape'])\n",
    "    if field['type'] == 'static':\n",
    "      data = tf.tile(data, [meta['trajectory_length'], 1, 1])\n",
    "    elif field['type'] == 'dynamic_varlen':\n",
    "      length = tf.io.decode_raw(features['length_'+key].values, tf.int32)\n",
    "      length = tf.reshape(length, [-1])\n",
    "      data = tf.RaggedTensor.from_row_lengths(data, row_lengths=length)\n",
    "    elif field['type'] != 'dynamic':\n",
    "      raise ValueError('invalid data format')\n",
    "    out[key] = data\n",
    "  return out\n",
    "\n",
    "\n",
    "def load_dataset(split):\n",
    "  \"\"\"Load dataset.\"\"\"\n",
    "  with open(os.path.join(root_dir, dataset_folder+'meta.json'), 'r') as fp:\n",
    "    meta = json.loads(fp.read())\n",
    "  ds = tf.data.TFRecordDataset(os.path.join(root_dir, dataset_folder+split+'.tfrecord'))\n",
    "  ds = ds.map(functools.partial(_parse, meta=meta), num_parallel_calls=8)\n",
    "  ds = ds.prefetch(1)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b09627",
   "metadata": {},
   "source": [
    "## Lets look at the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48f337aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bbf800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.flat_map(tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a20813d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5dc44cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets fetch the dataset, and assign it to a variable 'l'\n",
    "l = list(ds.prefetch(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b02fa84",
   "metadata": {},
   "source": [
    "We can see that the size of test dataset is 60,000. Each item in the dataset is the data of corresponding timestep. Each Item of the dataset, is a dictionary containing 5 different type of data, specified as keys.They are:\n",
    "\n",
    "* cells : Shape is N1*3, where N1 is the number of traingular grids and 3 specifies the id of three nodes that are connected.\n",
    "* mesh_pos: Shape is N*2, where N is the number of nodes involved, and 2 species 2-D position coordinate of the node.\n",
    "* node_type: Shape is N*1 , specifying type of each node.\n",
    "* velocity: Shape is N*2, where N is the number of nodes involved, and 2 species 2-D velocity of flow at each node.\n",
    "* pressure: Shape is N*1, where N is the number of nodes involved, and 2 species 2-D pressure of flow at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fef432ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "#We can see that the size of test dataset is 60,000\n",
    "print(\"Size of dataset:\",len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ba56c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': <tf.Tensor: shape=(3612, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    7,    0],\n",
       "        ...,\n",
       "        [1917, 1915, 1516],\n",
       "        [1522, 1919, 1520],\n",
       "        [1919, 1917, 1520]])>,\n",
       " 'mesh_pos': <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>,\n",
       " 'node_type': <tf.Tensor: shape=(1923, 1), dtype=int32, numpy=\n",
       " array([[4],\n",
       "        [0],\n",
       "        [4],\n",
       "        ...,\n",
       "        [6],\n",
       "        [5],\n",
       "        [6]])>,\n",
       " 'velocity': <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.33411723, 0.        ],\n",
       "        [0.33384922, 0.23244236],\n",
       "        [0.16675676, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [1.1650559 , 0.00757535],\n",
       "        [0.        , 0.        ]], dtype=float32)>,\n",
       " 'pressure': <tf.Tensor: shape=(1923, 1), dtype=float32, numpy=\n",
       " array([[2.92446   ],\n",
       "        [3.1386888 ],\n",
       "        [3.0163872 ],\n",
       "        ...,\n",
       "        [0.01227513],\n",
       "        [0.13967943],\n",
       "        [0.14707252]], dtype=float32)>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concentrate on Shape of each data item\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89b3d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at data of two consequetive datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c92d591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3612, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    7,    0],\n",
       "        ...,\n",
       "        [1917, 1915, 1516],\n",
       "        [1522, 1919, 1520],\n",
       "        [1919, 1917, 1520]])>,\n",
       " <tf.Tensor: shape=(3276, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    0,    7],\n",
       "        ...,\n",
       "        [1751, 1749, 1342],\n",
       "        [1348, 1753, 1346],\n",
       "        [1753, 1751, 1346]])>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]['cells'] , l[600]['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "092bd66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that the correspoding position data of two consequetive timesteps are only slightly different\n",
    "l[0]['mesh_pos'] , l[1]['mesh_pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a28195",
   "metadata": {},
   "source": [
    "The dataset consists of episodes of 600 timesteps. Hence, we split the dataset at intervals of 600 to generate training data. Further we know that, the number of episodes is 60000/600 = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbb8c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset at intervals of 600 and the name the variable 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d880e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 100\n",
    "data = [l[i*600:600+i*600] for i in range(num_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b64ee84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at length of two different splits\n",
    "len(data[0]),len(data[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff0414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
