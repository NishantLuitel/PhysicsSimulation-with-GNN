{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acae4c10",
   "metadata": {},
   "source": [
    "# Understanding the Cylinder Flow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8888ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46fb5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52114689",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'Cylinder_flow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d64e6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adopted Functions from Deep mind to load the dataset\n",
    "def _parse(proto, meta):\n",
    "  \"\"\"Parses a trajectory from tf.Example.\"\"\"\n",
    "  feature_lists = {k: tf.io.VarLenFeature(tf.string)\n",
    "                   for k in meta['field_names']}\n",
    "  features = tf.io.parse_single_example(proto, feature_lists)\n",
    "  out = {}\n",
    "  for key, field in meta['features'].items():\n",
    "    data = tf.io.decode_raw(features[key].values, getattr(tf, field['dtype']))\n",
    "    data = tf.reshape(data, field['shape'])\n",
    "    if field['type'] == 'static':\n",
    "      data = tf.tile(data, [meta['trajectory_length'], 1, 1])\n",
    "    elif field['type'] == 'dynamic_varlen':\n",
    "      length = tf.io.decode_raw(features['length_'+key].values, tf.int32)\n",
    "      length = tf.reshape(length, [-1])\n",
    "      data = tf.RaggedTensor.from_row_lengths(data, row_lengths=length)\n",
    "    elif field['type'] != 'dynamic':\n",
    "      raise ValueError('invalid data format')\n",
    "    out[key] = data\n",
    "  return out\n",
    "\n",
    "\n",
    "def load_dataset(split):\n",
    "  \"\"\"Load dataset.\"\"\"\n",
    "  with open(os.path.join(root_dir, dataset_folder+'meta.json'), 'r') as fp:\n",
    "    meta = json.loads(fp.read())\n",
    "  ds = tf.data.TFRecordDataset(os.path.join(root_dir, dataset_folder+split+'.tfrecord'))\n",
    "  ds = ds.map(functools.partial(_parse, meta=meta), num_parallel_calls=8)\n",
    "  ds = ds.prefetch(1)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1caf94",
   "metadata": {},
   "source": [
    "## Lets look at the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88d8b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a1ae51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.flat_map(tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fd1c094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b4b8757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets fetch the dataset, and assign it to a variable 'l'\n",
    "l = list(ds.prefetch(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1d703",
   "metadata": {},
   "source": [
    "We can see that the size of test dataset is 60,000. Each item in the dataset is the data of corresponding timestep. Each Item of the dataset, is a dictionary containing 5 different type of data, specified as keys.They are:\n",
    "\n",
    "* cells : Shape is N1*3, where N1 is the number of traingular grids and 3 specifies the id of three nodes that are connected.\n",
    "* mesh_pos: Shape is N*2, where N is the number of nodes involved, and 2 species 2-D position coordinate of the node.\n",
    "* node_type: Shape is N*1 , specifying type of each node.\n",
    "* velocity: Shape is N*2, where N is the number of nodes involved, and 2 species 2-D velocity of flow at each node.\n",
    "* pressure: Shape is N*1, where N is the number of nodes involved, and 2 species 2-D pressure of flow at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef33f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "#We can see that the size of test dataset is 60,000\n",
    "print(\"Size of dataset:\",len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff83faff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': <tf.Tensor: shape=(3612, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    7,    0],\n",
       "        ...,\n",
       "        [1917, 1915, 1516],\n",
       "        [1522, 1919, 1520],\n",
       "        [1919, 1917, 1520]])>,\n",
       " 'mesh_pos': <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>,\n",
       " 'node_type': <tf.Tensor: shape=(1923, 1), dtype=int32, numpy=\n",
       " array([[4],\n",
       "        [0],\n",
       "        [4],\n",
       "        ...,\n",
       "        [6],\n",
       "        [5],\n",
       "        [6]])>,\n",
       " 'velocity': <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.33411723, 0.        ],\n",
       "        [0.33384922, 0.23244236],\n",
       "        [0.16675676, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        ],\n",
       "        [1.1650559 , 0.00757535],\n",
       "        [0.        , 0.        ]], dtype=float32)>,\n",
       " 'pressure': <tf.Tensor: shape=(1923, 1), dtype=float32, numpy=\n",
       " array([[2.92446   ],\n",
       "        [3.1386888 ],\n",
       "        [3.0163872 ],\n",
       "        ...,\n",
       "        [0.01227513],\n",
       "        [0.13967943],\n",
       "        [0.14707252]], dtype=float32)>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concentrate on Shape of each data item\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b116583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at data of two consequetive datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3144987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3612, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    7,    0],\n",
       "        ...,\n",
       "        [1917, 1915, 1516],\n",
       "        [1522, 1919, 1520],\n",
       "        [1919, 1917, 1520]])>,\n",
       " <tf.Tensor: shape=(3276, 3), dtype=int32, numpy=\n",
       " array([[   0,    1,    2],\n",
       "        [   3,    4,    5],\n",
       "        [   6,    0,    7],\n",
       "        ...,\n",
       "        [1751, 1749, 1342],\n",
       "        [1348, 1753, 1346],\n",
       "        [1753, 1751, 1346]])>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]['cells'] , l[600]['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4470743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1923, 2), dtype=float32, numpy=\n",
       " array([[0.        , 0.39398578],\n",
       "        [0.01234996, 0.39554158],\n",
       "        [0.        , 0.40217   ],\n",
       "        ...,\n",
       "        [1.5816092 , 0.41      ],\n",
       "        [1.6       , 0.40646887],\n",
       "        [1.6       , 0.41      ]], dtype=float32)>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that the correspoding position data of two consequetive timesteps are only slightly different\n",
    "l[0]['mesh_pos'] , l[1]['mesh_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
